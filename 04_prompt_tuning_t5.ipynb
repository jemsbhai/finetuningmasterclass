{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b212cc0d",
   "metadata": {},
   "source": [
    "# Prompt‑Tuning with FLAN‑T5 (PEFT)\n",
    "Learn soft prompt embeddings to steer a seq2seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U transformers datasets peft accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98740b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "from peft import PromptTuningConfig, TaskType, get_peft_model\n",
    "\n",
    "base = \"google/flan-t5-small\"\n",
    "tok = AutoTokenizer.from_pretrained(base)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny labeled dataset: sentiment-as-generation (positive/negative)\n",
    "rows = [\n",
    "    {\"input_text\": \"The movie was fantastic and moving.\", \"target_text\": \"positive\"},\n",
    "    {\"input_text\": \"The plot was dull and predictable.\", \"target_text\": \"negative\"},\n",
    "]*200\n",
    "ds = Dataset.from_list(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_cfg = PromptTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, num_virtual_tokens=20)\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3706db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ex):\n",
    "    m = tok(ex[\"input_text\"], truncation=True)\n",
    "    with tok.as_target_tokenizer():\n",
    "        labels = tok(ex[\"target_text\"], truncation=True)\n",
    "    m[\"labels\"] = labels[\"input_ids\"]\n",
    "    return m\n",
    "\n",
    "tok_ds = ds.map(preprocess, batched=True)\n",
    "collator = DataCollatorForSeq2Seq(tok, model=model)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"prompt-tuning-t5\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-4,\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=tok_ds, data_collator=collator, tokenizer=tok)\n",
    "trainer.train()\n",
    "model.save_pretrained(\"prompt-tuning-t5/model\")\n",
    "tok.save_pretrained(\"prompt-tuning-t5/tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference demo\n",
    "text = \"The acting was mediocre and the pacing slow.\"\n",
    "ids = tok(text, return_tensors=\"pt\").input_ids\n",
    "if torch.cuda.is_available(): ids = ids.cuda()\n",
    "gen = model.generate(ids, max_new_tokens=3)\n",
    "print(\"Prediction:\", tok.decode(gen[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
